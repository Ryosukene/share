{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81933ccc",
   "metadata": {},
   "source": [
    "http://neurotycho.org/expdatalist/listview?task=78の\n",
    "20110524KTMD_Anesthesia+and+Sleep_Kin2_Toru+Yanagawa_mat_ECoG128\n",
    "を\n",
    "$share/ECoGなどと名付けたフォルダ内にダウンロードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ダウンロードしたファイルをtrainとdevとtestに分ける\n",
    "import scipy.io\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import csv\n",
    "dataroot='$share/ECoG/20110524KTMD_Anesthesia+and+Sleep_Kin2_Toru+Yanagawa_mat_ECoG128/Session1/'\n",
    "root='$share/ECoG_training/Kin2_20110524_session1_CommonAve_ReginLabel/'\n",
    "test_list=[ 24, 62, 3, 49,11,  34, 54, 25, 53, 42, 50, 10, 8]\n",
    "train_list=[7, 0, 45, 29, 36, 38, 66, 60, 40, 13, 2, 4, 39, 41, 51, 18, 44, 1, 52,  33, 17, 46, 26, 19,  61, 55, 16, 57, 63, 23, 14, 5, 67,  27, 65, 32, 48, 21, 31, 64, 30, 20, 56, 9, 22,15, 28, 47, 43, 37, 58, 35, 59, 6, 12]\n",
    "\n",
    "region=[\n",
    "    [1,2,3,4,9,10,17,18,26,27,36,37,47,48,56,57],#LP\n",
    "    [5,6,7,8,11,12,13,14,19,20,21,22,28,29,38,39,49,50,65,66,74,75],#PM\n",
    "    [15,16,23,24,25,30,31,32,33,40,41,42,43,51,52,58,59,60,61,67,68,76,77],#MS\n",
    "    [34,35,44,45,53,54,55,64,69,70,71,72],#PC\n",
    "    [78,79,95,96,97,98,107,108,109,110,111,112,113,122,123,124,125,126,127,128],#TC\n",
    "    [73,83,84,80,81,82,99,100,101,102,114,115,116,117],#HV\n",
    "    [46,85,86,87,88,89,90,91,92,93,94,103,104,105,106,118,119,120,121]\n",
    "]\n",
    "electrodes=[region[i][j] for i in range(len(region)) for j in range(len(region[i])) ]\n",
    "num_electrodes=len(electrodes)\n",
    "#print(electrodes,num_electrodes)\n",
    "path=dataroot+'ECoG_ch1'+'.mat'\n",
    "data_ECoG_ch= scipy.io.loadmat(path)\n",
    "data=data_ECoG_ch['ECoGData_ch1'][0]\n",
    "len_data=len(data)\n",
    "lists_ECoG_CommonAve = np.array([0 for i in range(len_data)])\n",
    "#num_CommonAve=np.array([i+1 for i in range(num_electrodes)])\n",
    "\n",
    "for k in electrodes:\n",
    "    num=k\n",
    "    path=dataroot+'ECoG_ch'+str(num)+'.mat'\n",
    "    data_ECoG_ch= scipy.io.loadmat(path)\n",
    "    arg='ECoGData_ch'+str(num)    \n",
    "    data=data_ECoG_ch[arg][0]\n",
    "    print('data'+str(k),data)\n",
    "    data=np.array(data[:2800000])\n",
    "    lists_ECoG_CommonAve +=data\n",
    "    #print('lists_ECoG_CommonAve'+str(k),lists_ECoG_CommonAve)\n",
    "lists_ECoG_CommonAve=lists_ECoG_CommonAve/num_electrodes\n",
    "#print('lists_ECoG_CommonAve',lists_ECoG_CommonAve)\n",
    "\n",
    "for k in electrodes:\n",
    "    num=k\n",
    "    path=dataroot+'ECoG_ch'+str(num)+'.mat'\n",
    "    data_ECoG_ch= scipy.io.loadmat(path)\n",
    "    arg='ECoGData_ch'+str(num)    \n",
    "    data=data_ECoG_ch[arg][0]\n",
    "    data=np.array(data[:2800000])\n",
    "    data=data-lists_ECoG_CommonAve\n",
    "    #print('lists_ECoG_CommonAve',lists_ECoG_CommonAve)\n",
    "    #print('data'+str(k),data)\n",
    "    for j in train_list:\n",
    "        for i in range(len(region)):\n",
    "            if k in region[i]:\n",
    "                outpath=root+'train/'+str(i)+'/'+str(i)+'-'+str(k)+'-'+str(j)\n",
    "                print('outpath',outpath)\n",
    "        if not os.path.isdir(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        out_data=data[j*30000:j*30000+30000]\n",
    "        out_data = torch.tensor(out_data)\n",
    "        print('out_data',out_data)\n",
    "        torch.save(out_data, outpath+'.pt')         \n",
    "    for j in test_list:\n",
    "        for i in range(len(region)):\n",
    "            if k in region[i]:\n",
    "                outpath=root+'test/'+str(i)+'/'+str(i)+'-'+str(k)+'-'+str(j)\n",
    "                print('outpath',outpath)\n",
    "        if not os.path.isdir(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        out_data=data[j*30000:j*30000+30000]\n",
    "        out_data = torch.tensor(out_data)\n",
    "        print('out_data',out_data)\n",
    "        torch.save(out_data, outpath+'.pt')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SailiencyMapping_modules\n",
    "from SailiencyMapping_modules import  UpstreamExpert\n",
    "from SailiencyMapping_modules import _get_featurizer\n",
    "from SailiencyMapping_modules import _get_downstream\n",
    "from SailiencyMapping_modules import preprocess\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import requests\n",
    "from PIL import Image\n",
    "from upstream.mockingjay.builder_refine import PretrainedTransformer_refine\n",
    "from upstream.mockingjay.builder import PretrainedTransformer\n",
    "\n",
    "with open('options_arg_config.yaml', 'r') as yml:\n",
    "    options_arg_config = yaml.safe_load(yml)\n",
    "    \n",
    "#-----------extracter\n",
    "path=options_arg_config['path']\n",
    "load_weights = torch.load(path)\n",
    "self_config=load_weights['Upstream_Config']\n",
    "target_level=25\n",
    "region=6\n",
    "#------------PretrainedTransformer\n",
    "\n",
    "\n",
    "options=options_arg_config['options']\n",
    "Pretrainedtransformer_refine = PretrainedTransformer_refine(options, inp_dim=-1)\n",
    "\n",
    "upstreamexpert=UpstreamExpert().eval()\n",
    "featurizer=_get_featurizer().eval()\n",
    "downstream=_get_downstream().eval()\n",
    "#------------------------\n",
    "\n",
    "pth='$share/ECoG_training/Kin2_20110524_session1_CommonAve_ReginLabel/test/'+str(region)+'/'\n",
    "#pth='data/'+str(region)+'/'\n",
    "\n",
    "wavs=[]\n",
    "label=[]\n",
    "for i in [3,8,10,11,24,25,34,42]:\n",
    "    wav = torch.load(pth+str(region)+'-88-'+str(i)+'.pt')\n",
    "    print('wav',wav)\n",
    "    wav=torch.tensor(wav, dtype=torch.float32)\n",
    "    label.append(region)\n",
    "    wavs.append(wav)\n",
    "label=torch.tensor(label)\n",
    "wavs_=[torch.randn(16000) for i in range(8)]\n",
    "print('wavs_',wavs_)\n",
    "#wavs = [torch.FloatTensor(wav) for wav in wavs]\n",
    "x=preprocess(wavs,self_config)\n",
    "for i in range(len(x)):\n",
    "    plt.imshow(x[i])\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "#--------------------------\n",
    "x.requires_grad_()\n",
    "last_hidden_state,hidden_state=Pretrainedtransformer_refine(x)\n",
    "feature={\n",
    "    \"last_hidden_state\":last_hidden_state,\n",
    "    \"hidden_states\":hidden_state.unbind(dim=0),\n",
    "              }\n",
    "feature=featurizer(wavs,feature)\n",
    "\n",
    "scores=downstream(features=feature,labels=label,mode=eval)\n",
    "print('scores',scores)\n",
    "for i in range(len(scores)):\n",
    "    \n",
    "    score_max_index = scores[i].argmax()\n",
    "    print('score_max_index',score_max_index )\n",
    "    score_max = scores[i][score_max_index]\n",
    "    print('score_max',score_max)\n",
    "    score_max.backward(retain_graph=True)\n",
    "    saliency = x.grad.data.abs()\n",
    "    print('saliency',saliency)\n",
    "    plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
